{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install ipykernel\n",
    "%pip install pandas\n",
    "%pip install numpy\n",
    "%pip install matplotlib\n",
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import unicodedata\n",
    "import re\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category data\n",
    "category_data = pd.read_csv(\"castorama_categories.csv\")\n",
    "\n",
    "# Load products data\n",
    "product_data = pd.read_csv(\"castorama_products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm category data loaded correctly\n",
    "category_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm product data loaded correctly\n",
    "product_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "### Aperçu des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about category_data\n",
    "category_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about product_data\n",
    "product_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View category_data summary statistics \n",
    "category_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View product_data summary statistics \n",
    "product_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 data in category_data\n",
    "category_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 data in product_data\n",
    "product_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage et Préparation des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate raw data\n",
    "cdf = category_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "cdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View duplicated categories \n",
    "duplicates = cdf[cdf[\"category\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort duplicates to understand patterns\n",
    "duplicates.sort_values(by=['is_page_list','category', 'url'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by the specified columns\n",
    "cdf.sort_values(by=['is_page_list','category', 'url'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates (keep only first occurrence)\n",
    "cdf.drop_duplicates(subset=[\"category\"], inplace=True, keep='first')\n",
    "\n",
    "# View data\n",
    "cdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View duplicated urls\n",
    "duplicated_urls = cdf[cdf[\"url\"].duplicated(keep=False)]\n",
    "\n",
    "# Sort by url\n",
    "duplicates_sorted = duplicated_urls.sort_values(by=\"is_page_list\", ascending=False)\n",
    "\n",
    "# View data\n",
    "duplicates_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by \"is_page_list\"\n",
    "cdf.sort_values(by='is_page_list', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate urls (Observation: Double is_page_list created for SEO and Diacritics)\n",
    "\n",
    "cdf.drop_duplicates(subset=[\"url\"], inplace=True, keep='first')\n",
    "\n",
    "# Summarize data\n",
    "cdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nettoyage et Manipulation des Données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing spaces and characters in category name\n",
    "cdf[\"category\"] = cdf[\"category\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert category names to lowercase\n",
    "cdf['category'] = cdf['category'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling encoding issues (trailing underscores, Prefix 0s, multiple underscores) in specified columns\n",
    "# Replace spaces, commas, apostrophes with underscore\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Define function to clean category texts\n",
    "def clean_text(input_str):\n",
    "    \"\"\"\n",
    "    Standardize and clean text input by transforming special characters and whitespace.\n",
    "\n",
    "    Args:\n",
    "        input_str (str or None): Input string to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "        str or None: Cleaned string with standardized formatting.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If input is not a string, None, or NaN.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isnull(input_str):  # Handle NaN values\n",
    "            return input_str\n",
    "        \n",
    "        if not isinstance(input_str, (str, int, float)):\n",
    "            raise TypeError(f\"Expected string, got {type(input_str)}\")\n",
    "        \n",
    "        input_str = str(input_str)  # Ensure the input is a string\n",
    "        \n",
    "        input_str = re.sub(r'[\\u002D\\u2010\\u2011\\u2012\\u2013\\u2014\\u2212]', '_', input_str) # Replace all hyphen types\n",
    "        input_str = re.sub(r'\\s+', '_', input_str.strip()) # Replace all whitespace with underscores\n",
    "        input_str = input_str.replace(',', '_') # Replace commas with underscores \n",
    "        input_str = input_str.replace(\"'\", '_') # Replace apostrophes with underscores\n",
    "        input_str = re.sub(r'_+', '_', input_str) # Remove multiple underscores\n",
    "        input_str = re.sub(r'^_|_$', '', input_str) # Remove leading or trailing underscores\n",
    "        input_str = re.sub(r'^0+', '', input_str) # Remove leading zeros\n",
    "        \n",
    "        return input_str\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in category clean_text: {e}\")\n",
    "        raise\n",
    "\n",
    "# Apply function to clean category text\n",
    "cdf['category'] = cdf['category'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare text replacement characters\n",
    "replacements = {\"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ä\": \"a\", \"ç\" : \"c\",\n",
    "                \"é\": \"e\", \"è\": \"e\", \"ê\": \"e\", \"ë\": \"e\", \"É\":\"E\", \"È\":\"E\",\n",
    "                \"î\": \"i\", \"ï\":\"i\", \"ì\": \"i\", \"í\": \"i\",\n",
    "                \"ö\": \"o\", \"ô\": \"o\", \"ò\": \"o\", \"ó\": \"o\",\n",
    "                \"ü\": \"u\", \"û\": \"u\", \"ù\": \"u\", \"ú\": \"u\"}\n",
    "\n",
    "# Define function to replace accented category texts\n",
    "def replace_accents(input_str, replacement):\n",
    "    \"\"\"\n",
    "    Replace specific accented characters in a string using a provided replacement dictionary.\n",
    "\n",
    "    Args:\n",
    "        input_str (str): Input string to be processed.\n",
    "        replacement (dict): Dictionary mapping accented characters to their replacements.\n",
    "\n",
    "    Returns:\n",
    "        str: String with specified characters replaced.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If input_str is not a string or replacement is not a dictionary.\n",
    "        ValueError: If replacement dictionary is empty.\n",
    "\n",
    "    Examples:\n",
    "        >>> replacements = {'é': 'e', 'à': 'a'}\n",
    "        >>> replace_accents(\"Café\", replacements)\n",
    "        'Cafe'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input types\n",
    "        if not isinstance(input_str, str):\n",
    "            raise TypeError(f\"Expected string for input_str, got {type(input_str)}\")\n",
    "        \n",
    "        if not isinstance(replacement, dict):\n",
    "            raise TypeError(f\"Expected dictionary for replacement, got {type(replacement)}\")\n",
    "        \n",
    "        if not replacement:\n",
    "            raise ValueError(\"Replacement dictionary cannot be empty\")\n",
    "\n",
    "        # Perform replacements\n",
    "        for old, new in replacement.items():\n",
    "            input_str = input_str.replace(old, new)\n",
    "        \n",
    "        return input_str\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in category replace_accents: {e}\")\n",
    "        raise\n",
    "\n",
    "# Apply function to remove accents\n",
    "cdf[\"category\"] = cdf[\"category\"].apply(lambda x: replace_accents(str(x), replacements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review for errors or duplicates\n",
    "cdf.sort_values(by='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify again if duplicates persists\n",
    "c_duplicates = cdf[cdf['category'].duplicated(keep=False)]\n",
    "\n",
    "# Sort by category\n",
    "c_duplicates.sort_values(by='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by is_page_list\n",
    "cdf_sorted = cdf.sort_values(by=\"is_page_list\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop newly found duplicates (SEO / Diacritics related, keep only \"True\" is_page_lists)\n",
    "cdf_no_duplicates = cdf_sorted.drop_duplicates(subset=['category'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by original index\n",
    "cdf_no_duplicates = cdf_no_duplicates.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate original index\n",
    "cdf_no_duplicates[\"original_index\"] = cdf_no_duplicates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "categories_cleaned = cdf_no_duplicates.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude original index from final copy\n",
    "categories_cleaned_final = categories_cleaned[['category', 'is_page_list', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data\n",
    "categories_cleaned_final.to_csv(\"categories_cleaned_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate raw product data\n",
    "pdf = product_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info about products data\n",
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics/info\n",
    "pdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (general)\n",
    "pdf.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in unique_id column\n",
    "pdf[\"unique_id\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (category column)\n",
    "pdf[\"category\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (subcategory column)\n",
    "pdf[\"subcategory\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (subsubcategory column)\n",
    "pdf[\"subsubcategory\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (subsubsubcategory column)\n",
    "pdf[\"subsubsubcategory\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (price column)\n",
    "pdf[\"price\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (title column) \n",
    "pdf[\"title\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (url column)\n",
    "pdf[\"url\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics\n",
    "pdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View duplicates (if any)\n",
    "duplicates_in_pdf = pdf[pdf.duplicated(subset=\"title\", keep=False)]\n",
    "\n",
    "duplicates_in_pdf\n",
    "\n",
    "# Note: Duplicates were not removed because each entry represents a distinct variation of a product (e.g., different color or size) with a unique ID. \n",
    "# While some fields like title, category, or subcategory may be identical, these variations provide important granularity for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Nettoyage et Manipulation des Données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs\n",
    "pdf['subsubsubcategory'] = pdf['subsubsubcategory'].fillna(\"Not_available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specified columns to lowercase \n",
    "columns_to_lowercase = ['category', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title']\n",
    "pdf[columns_to_lowercase] = pdf[columns_to_lowercase].apply(lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip values in the specified columns \n",
    "columns_to_strip = ['category', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title']\n",
    "pdf[columns_to_strip] = pdf[columns_to_strip].apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling encoding issues (trailing underscores, Prefix 0s, multiple underscores) in specified columns\n",
    "# Replace spaces, commas, apostrophes with underscore\n",
    "\n",
    "\n",
    "columns_to_replace = ['category', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title']\n",
    "\n",
    "# Apply \"clean_text\" function to specified columns\n",
    "pdf[columns_to_replace] = pdf[columns_to_replace].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace accented letters in the specified columns' texts\n",
    "\n",
    "def robust_remove_accents(input_str):\n",
    "    \"\"\"\n",
    "    Remove accented characters from input string, converting to their base ASCII equivalents.\n",
    "\n",
    "    Args:\n",
    "        input_str (str): Input string containing accented characters.\n",
    "\n",
    "    Returns:\n",
    "        str: String with accented characters replaced by their non-accented equivalents.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If input is not a string.\n",
    "        ValueError: If input processing fails.\n",
    "\n",
    "    Examples:\n",
    "        >>> robust_remove_accents(\"héllô\")\n",
    "        'hello'\n",
    "        >>> robust_remove_accents(\"Café\")\n",
    "        'Cafe'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate input type\n",
    "        if not isinstance(input_str, str):\n",
    "            raise TypeError(f\"Expected string, got {type(input_str)}\")\n",
    "\n",
    "        # Normalize to decomposed form\n",
    "        normalized = unicodedata.normalize('NFD', input_str)\n",
    "\n",
    "        # Remove combining characters (accents)\n",
    "        without_accents = ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "        # Explicitly replace problematic characters (if any remains)\n",
    "        replacements = {\"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ä\": \"a\", \"ç\": \"c\", \"ć\": \"c\",\n",
    "                    \"é\": \"e\", \"è\": \"e\", \"ê\": \"e\", \"ë\": \"e\", \"É\":\"E\", \"È\":\"E\",\n",
    "                    \"î\": \"i\", \"ï\":\"i\", \"ì\": \"i\", \"í\": \"i\",\n",
    "                    \"ö\": \"o\", \"ô\": \"o\", \"ò\": \"o\", \"ó\": \"o\",\n",
    "                    \"ü\": \"u\", \"û\": \"u\", \"ù\": \"u\", \"ú\": \"u\"}\n",
    "\n",
    "        for accented_char, replacement in replacements.items():\n",
    "            without_accents = without_accents.replace(accented_char, replacement)\n",
    "        \n",
    "        # Handle lingering issues and strip\n",
    "        return without_accents.replace('\\xa0', ' ').strip()\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in product robust_remove_accents: {e}\")\n",
    "        raise\n",
    "\n",
    "# Apply function\n",
    "pdf[columns_to_replace] = pdf[columns_to_replace].map(\n",
    "    lambda x: robust_remove_accents(str(x)) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace commans with full stops and remove spaces bewteen numbers\n",
    "pdf['price'] = pdf['price'].apply(lambda x: x.replace(\",\", \".\"))\n",
    "pdf['price'] = pdf['price'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "# Convert price column to float type\n",
    "pdf['price'] = pd.to_numeric(pdf['price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display count of prices with NaN\n",
    "pdf['price'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with NaNs to understand the problem\n",
    "pdf_nas = pdf[pdf.isna().any(axis=1)]\n",
    "\n",
    "pdf_nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with None\n",
    "pdf['price'] = pdf['price'].replace({pd.NA: None, np.nan: None})\n",
    "\n",
    "# Drop rows with NaN\n",
    "pdf = pdf.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store copy of original index\n",
    "pdf['original_index'] = pdf.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "products_cleaned = pdf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure price is in float format\n",
    "products_cleaned['price'] = pd.to_numeric(products_cleaned['price'], errors='coerce')\n",
    "\n",
    "# Select specific columns to be saved to the final file\n",
    "products_cleaned_final = products_cleaned[['unique_id','category','subcategory', 'subsubcategory', 'subsubsubcategory', 'title', 'price', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned file to csv\n",
    "products_cleaned_final.to_csv(\"products_cleaned_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse et visualisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categories.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "cat = pd.read_csv(\"categories_cleaned_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the raw data\n",
    "cat_df = cat.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of page_lists\n",
    "pagelist_num = cat_df['is_page_list'].value_counts()\n",
    "\n",
    "# Store result in dataframe\n",
    "pagelist_num = pd.DataFrame(pagelist_num)\n",
    "\n",
    "# Reset dataframe index\n",
    "pagelist_num = pagelist_num.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataframe\n",
    "pagelist_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Products.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "prod = pd.read_csv(\"products_cleaned_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the raw data\n",
    "prod_df = prod.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view data\n",
    "prod_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show summary statistics\n",
    "prod_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of products by category\n",
    "len_products = prod_df.groupby('category').size()\n",
    "\n",
    "# Make table a dataframe\n",
    "products_len_df = pd.DataFrame(len_products, columns=[\"num_of_products\"]).reset_index()\n",
    "\n",
    "# Show dataframe\n",
    "products_len_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bar chart showing the number of products by category\n",
    "\n",
    "# override the default matplotlib style, to avoid the grey background and grid\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "# Plot number of products\n",
    "sns.barplot(products_len_df, x = 'num_of_products', y = 'category', color=\"blue\")\n",
    "\n",
    "# Add labels, title, and adjust axes params\n",
    "plt.title('Number of Products by Category', fontsize = 13, weight = \"bold\")\n",
    "plt.ylabel('Category', fontsize = 10)\n",
    "plt.xlabel('Number of products', fontsize = 10)\n",
    "plt.yticks(fontsize = 10)\n",
    "plt.xticks(fontsize = 10)\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error bar showing mean & standard deviation by category\n",
    "\n",
    "# override the default matplotlib style, to avoid the grey background and grid\n",
    "sns.set_style(\"white\") \n",
    "\n",
    "# Group by category and calculate statistics\n",
    "stats = prod_df.groupby('category')['price'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "\n",
    "# Plot mean with horizontal error bars for std deviation\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.errorbar(\n",
    "    stats['mean'], stats['category'], \n",
    "    xerr=stats['std'], fmt='o', capsize=4, label='Mean ± Std Dev', color='blue', elinewidth=0.8\n",
    ")\n",
    "\n",
    "# Adjust plot border width\n",
    "for spine in plt.gca().spines.values():  # Access all spines\n",
    "    spine.set_linewidth(0.5)  # Set the border (spine) line width\n",
    "\n",
    "# Add labels, title, and adjust axes params\n",
    "plt.title('Mean & Standard Deviation by Category', fontsize = 13, weight = \"bold\")\n",
    "plt.ylabel('Category', fontsize = 10)\n",
    "plt.xlabel('Price (€)', fontsize = 10)\n",
    "plt.yticks(fontsize = 10)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.legend()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot range chart showing price range by category\n",
    "\n",
    "# override the default matplotlib style, to avoid the grey background and grid\n",
    "sns.set_style(\"white\") \n",
    "\n",
    "# Prepare the y positions, x_bot, and x_dif\n",
    "y = np.arange(len(stats))  # positions for the categories\n",
    "x_bot = stats['min']       # minimum price as the start of the bar\n",
    "x_dif = stats['max'] - stats['min']  # range of the prices as the bar width\n",
    "\n",
    "# Create the horizontal bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(y, x_dif, left=x_bot, color='skyblue', edgecolor='blue', height=0.01)\n",
    "\n",
    "# Adjust plot border width\n",
    "for spine in plt.gca().spines.values():  # Access all spines\n",
    "    spine.set_linewidth(0.5)  # Set the border (spine) line width\n",
    "\n",
    "# Add labels, title, and adjust axes params\n",
    "plt.title('Price Range by Category', fontsize = 13, weight = \"bold\")\n",
    "plt.ylabel('Category', fontsize = 10)  # Label for the y-axis\n",
    "plt.xlabel('Price Range (€)', fontsize = 10)  # Label for the x-axis\n",
    "plt.yticks(y, stats['category'], fontsize = 10)\n",
    "plt.xticks(fontsize = 10)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get product details for the least and most expensive products by category\n",
    "min_products = prod_df.loc[prod_df.groupby('category')['price'].idxmin(), ['category', 'title', 'price']]\n",
    "max_products = prod_df.loc[prod_df.groupby('category')['price'].idxmax(), ['category', 'title', 'price']]\n",
    "\n",
    "# Merge min and max product details\n",
    "min_max_products = pd.merge(\n",
    "    min_products,\n",
    "    max_products,\n",
    "    on='category',\n",
    "    suffixes=('_min', '_max')\n",
    ")\n",
    "\n",
    "# Display table as dataframe\n",
    "pd.DataFrame(min_max_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the size of each category\n",
    "category_counts = prod_df.groupby('category').size()\n",
    "\n",
    "# Filter for categories with more than 500 products\n",
    "categories_to_keep = category_counts[category_counts > 500].index\n",
    "\n",
    "# Filter the original DataFrame\n",
    "filtered_df = prod_df[prod_df['category'].isin(categories_to_keep)]\n",
    "\n",
    "#  Select the first 500 rows per category\n",
    "filtered_df = (\n",
    "    filtered_df.sort_values(by=['category', 'price'])  # Sort by category and optionally by price\n",
    "    .groupby('category')                              # Group by category\n",
    "    .head(500)                                        # Take the first 200 rows per category\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of unwanted columns\n",
    "columns_to_drop = ['unique_id', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title', 'url']\n",
    "\n",
    "# Drop unwanted columns\n",
    "filtered_df = filtered_df.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to ensure sequential indexing\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "# Create pivot table\n",
    "pivoted = filtered_df.pivot_table(index=filtered_df.index % 500, columns='category', values='price', aggfunc='first')\n",
    "\n",
    "# Show pivot table\n",
    "pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate category prices\n",
    "category_corr = pivoted.corr()\n",
    "\n",
    "# Show correlation table\n",
    "category_corr\n",
    "\n",
    "# Note: Correlation was carried out among categories with at least 500 products to see the relationship between category pricing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot heatmap to show category correlation matrix\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(category_corr.select_dtypes('number').corr(), \n",
    "            annot=True,\n",
    "            cmap=\"Blues\",\n",
    "            fmt=\".2f\",\n",
    "            linewidths=.5)\n",
    "\n",
    "# Add labels, title, and adjust axes params\n",
    "plt.title(\"Heat map of correlation matrix\", fontsize = 13, weight = \"bold\")\n",
    "plt.xlabel('Category', fontsize = 10)\n",
    "plt.ylabel('Category', fontsize = 10)\n",
    "plt.xticks(fontsize = 10)\n",
    "plt.yticks(fontsize = 10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
