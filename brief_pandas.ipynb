{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief Métier : Exploitation des Données Scrappées avec Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexte Professionnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après la phase de **scraping** réalisée sur des sites concurrents de Castorama, vous avez obtenu deux fichiers CSV :\n",
    "\n",
    "- categories.csv : contenant les informations relatives aux catégories et sous-catégories.\n",
    "- products.csv : contenant les informations relatives aux produits (nom, prix, disponibilité, promotions, etc.).\n",
    "\n",
    "En tant que **Data Analyst / Data Engineer**, votre rôle est désormais de **nettoyer**, **préparer** et **analyser** ces données afin d’en extraire des **informations pertinentes**. Ces informations permettront à Castorama de mieux comprendre l’état du marché, de mettre en place une stratégie tarifaire compétitive et d'anticiper les tendances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install ipykernel\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category data\n",
    "\n",
    "category_data = pd.read_csv(\"castorama_categories.csv\")\n",
    "\n",
    "# Load products data\n",
    "\n",
    "product_data = pd.read_csv(\"castorama_products.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm category data loaded correctly\n",
    "\n",
    "category_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm product data loaded correctly\n",
    "\n",
    "product_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration\n",
    "\n",
    "### Aperçu des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about category_data\n",
    "\n",
    "category_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about product_data\n",
    "\n",
    "product_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View category_data summary statistics \n",
    "\n",
    "category_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View product_data summary statistics \n",
    "\n",
    "product_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 data in category_data\n",
    "\n",
    "category_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first 5 data in product_data\n",
    "\n",
    "product_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage et Préparation des Données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate raw data\n",
    "\n",
    "cdf = category_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "\n",
    "cdf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View duplicated categories \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "duplicates = cdf[cdf[\"category\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort duplicates to understand patterns\n",
    "\n",
    "duplicates.sort_values(by=['is_page_list','category', 'url'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by the specified columns\n",
    "\n",
    "cdf.sort_values(by=['is_page_list','category', 'url'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates (keep only first occurrence)\n",
    "\n",
    "cdf.drop_duplicates(subset=[\"category\"], inplace=True, keep='first')\n",
    "\n",
    "# View data\n",
    "cdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View duplicated urls\n",
    "\n",
    "duplicated_urls = cdf[cdf[\"url\"].duplicated(keep=False)]\n",
    "\n",
    "# Sort by url\n",
    "duplicates_sorted = duplicated_urls.sort_values(by=\"is_page_list\", ascending=False)\n",
    "\n",
    "# View data\n",
    "duplicates_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by \"is_page_list\"\n",
    "\n",
    "cdf.sort_values(by='is_page_list', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate urls (Observation: Double is_page_list created for SEO and Diacritics)\n",
    "\n",
    "cdf.drop_duplicates(subset=[\"url\"], inplace=True, keep='first')\n",
    "\n",
    "# Summarize data\n",
    "cdf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manipulation de chaînes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove trailing spaces and characters in category name\n",
    "\n",
    "cdf[\"category\"] = cdf[\"category\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert category names to lowercase\n",
    "\n",
    "cdf['category'] = cdf['category'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling encoding issues (trailing underscores, Prefix 0s, multiple underscores) in specified columns\n",
    "# Replace spaces, commas, apostrophes with underscore\n",
    "\n",
    "import re\n",
    "\n",
    "def clean_text(input_str):\n",
    "    if pd.isnull(input_str):  # Handle NaN values\n",
    "        return input_str\n",
    "    input_str = str(input_str)  # Ensure the input is a string\n",
    "    input_str = re.sub(r'[\\u002D\\u2010\\u2011\\u2012\\u2013\\u2014\\u2212]', '_', input_str) # Replace all hyphen types\n",
    "    input_str = re.sub(r'\\s+', '_', input_str.strip())  # Replace all whitespace with underscores\n",
    "    input_str = input_str.replace(',', '_')  # Replace commas with underscores\n",
    "    input_str = input_str.replace(\"'\", '_')  # Replace apostrophes with underscores\n",
    "    input_str = input_str.replace('\\xa0', '_')  # Replace non-breaking spaces\n",
    "    input_str = re.sub(r'_+', '_', input_str)  # Remove multiple underscores\n",
    "    input_str = re.sub(r'^_|_$', '', input_str)  # Remove leading or trailing underscores\n",
    "    input_str = re.sub(r'^0+', '', input_str)  # Remove leading zeros\n",
    "    return input_str\n",
    "\n",
    "cdf['category'] = cdf['category'].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accents\n",
    "\n",
    "replacements = {\"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ä\": \"a\", \"ç\" : \"c\",\n",
    "                \"é\": \"e\", \"è\": \"e\", \"ê\": \"e\", \"ë\": \"e\", \"É\":\"E\", \"È\":\"E\",\n",
    "                \"î\": \"i\", \"ï\":\"i\", \"ì\": \"i\", \"í\": \"i\",\n",
    "                \"ö\": \"o\", \"ô\": \"o\", \"ò\": \"o\", \"ó\": \"o\",\n",
    "                \"ü\": \"u\", \"û\": \"u\", \"ù\": \"u\", \"ú\": \"u\"}\n",
    "\n",
    "def replace_accents(input_str, replacement):\n",
    "    for old, new in replacement.items():\n",
    "        input_str = input_str.replace(old, new)\n",
    "    return input_str\n",
    "\n",
    "cdf[\"category\"] = cdf[\"category\"].apply(lambda x: replace_accents(str(x), replacements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review for errors or duplicates\n",
    "\n",
    "cdf.sort_values(by='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify again if duplicates persists\n",
    "\n",
    "c_duplicates = cdf[cdf['category'].duplicated(keep=False)]\n",
    "\n",
    "c_duplicates.sort_values(by='category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by is_page_list\n",
    "\n",
    "cdf_sorted = cdf.sort_values(by=\"is_page_list\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop newly found duplicates (SEO / Diacritics related, keep only \"True\" is_page_lists)\n",
    "\n",
    "cdf_no_duplicates = cdf_sorted.drop_duplicates(subset=['category'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by original index\n",
    "\n",
    "cdf_no_duplicates = cdf_no_duplicates.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate original index\n",
    "\n",
    "cdf_no_duplicates[\"original_index\"] = cdf_no_duplicates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "\n",
    "categories_cleaned = cdf_no_duplicates.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude original index from final copy\n",
    "\n",
    "categories_cleaned_final = categories_cleaned[['category', 'is_page_list', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data\n",
    "\n",
    "categories_cleaned_final.to_csv(\"categories_cleaned_final.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicate raw product data\n",
    "\n",
    "pdf = product_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info about products data\n",
    "\n",
    "pdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary statistics/info\n",
    "\n",
    "pdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (general)\n",
    "\n",
    "pdf.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in unique_id column\n",
    "\n",
    "pdf[\"unique_id\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (category column)\n",
    "\n",
    "pdf[\"category\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (subcategory column)\n",
    "\n",
    "pdf[\"subcategory\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (subsubcategory column)\n",
    "\n",
    "pdf[\"subsubcategory\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (subsubsubcategory column)\n",
    "\n",
    "pdf[\"subsubsubcategory\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (price column)\n",
    "\n",
    "pdf[\"price\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (title column) \n",
    "\n",
    "pdf[\"title\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values (url column)\n",
    "\n",
    "pdf[\"url\"].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Manipulation de chaînes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs\n",
    "\n",
    "pdf['subsubsubcategory'] = pdf['subsubsubcategory'].fillna(\"Not_available\")\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert specified columns to lowercase \n",
    "\n",
    "columns_to_lowercase = ['category', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title']\n",
    "\n",
    "pdf[columns_to_lowercase] = pdf[columns_to_lowercase].apply(lambda x: x.str.lower())\n",
    "\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip values in the specified columns \n",
    "\n",
    "columns_to_strip = ['category', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title']\n",
    "\n",
    "pdf[columns_to_strip] = pdf[columns_to_strip].apply(lambda x: x.str.strip())\n",
    "\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling encoding issues (trailing underscores, Prefix 0s, multiple underscores) in specified columns\n",
    "# Replace spaces, commas, apostrophes with underscore\n",
    "\n",
    "import re\n",
    "\n",
    "columns_to_replace = ['category', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title']\n",
    "\n",
    "def clean_text(input_str):\n",
    "    if pd.isnull(input_str):  # Handle NaN values\n",
    "        return input_str\n",
    "    input_str = str(input_str)  # Ensure the input is a string\n",
    "    input_str = re.sub(r'[\\u002D\\u2010\\u2011\\u2012\\u2013\\u2014\\u2212]', '_', input_str) # Replace all hyphen types\n",
    "    input_str = re.sub(r'\\s+', '_', input_str.strip())  # Replace all whitespace with underscores\n",
    "    input_str = input_str.replace(',', '_')  # Replace commas with underscores\n",
    "    input_str = input_str.replace(\"'\", '_')  # Replace apostrophes with underscores\n",
    "    input_str = re.sub(r'_+', '_', input_str)  # Remove multiple underscores\n",
    "    input_str = re.sub(r'^_|_$', '', input_str)  # Remove leading or trailing underscores\n",
    "    input_str = re.sub(r'^0+', '', input_str)  # Remove leading zeros\n",
    "    return input_str\n",
    "\n",
    "pdf[columns_to_replace] = pdf[columns_to_replace].map(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace accented letters in the specified columns' texts\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "columns_to_replace = ['category', 'subcategory', 'subsubcategory', 'subsubsubcategory', 'title']\n",
    "\n",
    "def robust_remove_accents(input_str):\n",
    "    # Normalize to decomposed form\n",
    "    normalized = unicodedata.normalize('NFD', input_str)\n",
    "    # Remove combining characters (accents)\n",
    "    without_accents = ''.join(c for c in normalized if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "    # Explicitly replace problematic characters (if any remains)\n",
    "    replacements = {\"à\": \"a\", \"á\": \"a\", \"â\": \"a\", \"ä\": \"a\",\n",
    "                \"é\": \"e\", \"è\": \"e\", \"ê\": \"e\", \"ë\": \"e\", \"É\":\"E\", \"È\":\"E\",\n",
    "                \"î\": \"i\", \"ï\":\"i\", \"ì\": \"i\", \"í\": \"i\",\n",
    "                \"ö\": \"o\", \"ô\": \"o\", \"ò\": \"o\", \"ó\": \"o\",\n",
    "                \"ü\": \"u\", \"û\": \"u\", \"ù\": \"u\", \"ú\": \"u\"}\n",
    "\n",
    "    for accented_char, replacement in replacements.items():\n",
    "        without_accents = without_accents.replace(accented_char, replacement)\n",
    "    \n",
    "    # Handle lingering issues and strip\n",
    "    return without_accents.replace('\\xa0', ' ').strip()\n",
    "\n",
    "pdf[columns_to_replace] = pdf[columns_to_replace].map(\n",
    "    lambda x: robust_remove_accents(str(x)) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert price column to float type\n",
    "\n",
    "pdf['price'] = pdf['price'].apply(lambda x: x.replace(\",\", \".\"))\n",
    "pdf['price'] = pdf['price'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "pdf['price'] = pd.to_numeric(pdf['price'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display count of prices with NaN\n",
    "\n",
    "pdf['price'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show rows with NaNs to understand the problem\n",
    "\n",
    "pdf_nas = pdf[pdf.isna().any(axis=1)]\n",
    "\n",
    "pdf_nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with None\n",
    "\n",
    "pdf['price'] = pdf['price'].replace({pd.NA: None, np.nan: None})\n",
    "\n",
    "# Drop rows with NaN\n",
    "pdf = pdf.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "\n",
    "pdf.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
